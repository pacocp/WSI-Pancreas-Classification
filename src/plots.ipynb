{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97fdbc3a",
   "metadata": {},
   "source": [
    "# Plots and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1585c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve,RocCurveDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2899187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True,\n",
    "                          filename='plot.png'):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.savefig(filename, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94cbbff",
   "metadata": {},
   "source": [
    "## 10-Fold CV experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('runs/tcia_kfold_patient/test_results.pkl', 'rb') as f:\n",
    "    data_tcia = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbefb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('runs/tcgagtex_kfold_patient/test_results.pkl', 'rb') as f:\n",
    "    data_tcga_gtex = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39c8cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "real = []\n",
    "accs = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "probabilities = []\n",
    "for split in data_tcia.keys():\n",
    "    test = data_tcia[split]\n",
    "    real_test = np.concatenate(data_tcga_gtex[split]['real'], axis=0).astype(np.int32)\n",
    "    preds = np.concatenate(data_tcga_gtex[split]['predictions'], axis=0).astype(np.int32)\n",
    "    patient_ids = np.concatenate(data_tcga_gtex[split]['patient_ids'], axis=0)\n",
    "    probs = np.concatenate(data_tcga_gtex[split]['outputs'],axis=0).astype(np.float32)\n",
    "    new_preds = []\n",
    "    new_real = []\n",
    "    new_outputs = []\n",
    "    for pidx in np.unique(patient_ids):\n",
    "        index = np.where(patient_ids == pidx)[0]\n",
    "        if len(index) == 1:\n",
    "            new_preds.append(preds[index[0]])\n",
    "            new_real.append(real_test[index[0]])\n",
    "            new_outputs.append(probs[index[0]])\n",
    "        else:\n",
    "            new_probs = np.mean(probs[index], axis=0)\n",
    "            n_ = softmax(new_probs)\n",
    "            new_outputs.append(n_)\n",
    "            new_preds.append(np.argmax(n_))\n",
    "            new_real.append(real_test[index[0]])\n",
    "    \n",
    "    acc = accuracy_score(new_real, new_preds)\n",
    "    f1 = f1_score(new_real, new_preds, average=\"weighted\")\n",
    "    auc = roc_auc_score(new_real, new_preds)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)\n",
    "    aucs.append(auc)\n",
    "    real.append(new_real)\n",
    "    outputs.append(new_preds)\n",
    "    probabilities.append(new_outputs)\n",
    "\n",
    "print(f'TCGA + GTEX')\n",
    "print(f'Acc {round(np.mean(acc)*100,3)} +- {round(np.std(accs)*100, 3)}')\n",
    "print(f'F1-score {round(np.mean(f1s)*100,3)} +- {round(np.std(f1s)*100, 3)}')\n",
    "print(f'AUC {round(np.mean(aucs),3)}+- {round(np.std(aucs), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a92ac88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "real = [item for sublist in real for item in sublist]\n",
    "outputs = [item for sublist in outputs for item in sublist]\n",
    "probs = [item for sublist in probabilities for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ab3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(real, outputs)\n",
    "f1 = f1_score(real, outputs)\n",
    "auc = roc_auc_score(real, outputs)\n",
    "print('TCGA-GTEX 10-fold CV results')\n",
    "print(f'Acc {round(acc*100,3)}')\n",
    "print(f'F1-score {round(f1*100,3)}')\n",
    "print(f'AUC {round(auc,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28b3e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_outputs = np.array(probs)\n",
    "fpr, tpr, _ = roc_curve(real, new_outputs[:,1])\n",
    "auc = round(roc_auc_score(real, outputs), 3)\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr,label=\"TCGA+GTEx, AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('plots/tcgagtex_10foldcv_roccurve_patient', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02ecef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(real, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e0ef5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, target_names = ['Control', 'Tumor'], normalize = False, filename = 'plots/cm_10fold_tcgagtex_patient.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7139c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "random.seed(99)\n",
    "outputs = []\n",
    "real = []\n",
    "accs = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "probabilities = []\n",
    "for split in data_tcia.keys():\n",
    "    test = data_tcia[split]\n",
    "    real_test = np.concatenate(data_tcia[split]['real'], axis=0).astype(np.int32)\n",
    "    preds = np.concatenate(data_tcia[split]['predictions'], axis=0).astype(np.int32)\n",
    "    patient_ids = np.concatenate(data_tcia[split]['patient_ids'], axis=0)\n",
    "    probs = np.concatenate(data_tcia[split]['outputs'],axis=0).astype(np.float32)\n",
    "    new_preds = []\n",
    "    new_real = []\n",
    "    new_outputs = []\n",
    "    for pidx in np.unique(patient_ids):\n",
    "        index = np.where(patient_ids == pidx)[0]\n",
    "        if len(index) == 1:\n",
    "            new_preds.append(preds[index[0]])\n",
    "            new_real.append(real_test[index[0]])\n",
    "            new_outputs.append(probs[index[0]])\n",
    "        else:\n",
    "            new_probs = np.mean(probs[index], axis=0)\n",
    "            n_ = softmax(new_probs)\n",
    "            new_outputs.append(n_)\n",
    "            new_preds.append(np.argmax(n_))\n",
    "            new_real.append(real_test[index[0]])\n",
    "    \n",
    "    acc = accuracy_score(new_real, new_preds)\n",
    "    f1 = f1_score(new_real, new_preds, average=\"weighted\")\n",
    "    auc = roc_auc_score(new_real, new_preds)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)\n",
    "    aucs.append(auc)\n",
    "    real.append(new_real)\n",
    "    outputs.append(new_preds)\n",
    "    probabilities.append(new_outputs)\n",
    "\n",
    "print(f'CPTAC')\n",
    "print(f'Acc {round(np.mean(acc)*100,3)} +- {round(np.std(accs)*100, 3)}')\n",
    "print(f'F1-score {round(np.mean(f1s)*100,3)} +- {round(np.std(f1s)*100, 3)}')\n",
    "print(f'AUC {round(np.mean(aucs),3)}+- {round(np.std(aucs), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663c060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real = [item for sublist in real for item in sublist]\n",
    "outputs = [item for sublist in outputs for item in sublist]\n",
    "new_outputs = [item for sublist in probabilities for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdcf5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(real, outputs)\n",
    "f1 = f1_score(real, outputs)\n",
    "auc = roc_auc_score(real, outputs)\n",
    "print('CPTAC 10-fold CV results')\n",
    "print(f'Acc {round(acc*100,3)}')\n",
    "print(f'F1-score {round(f1*100,3)}')\n",
    "print(f'AUC {round(auc,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_outputs = np.array(new_outputs)\n",
    "fpr, tpr, _ = roc_curve(real, new_outputs[:,1])\n",
    "auc = round(roc_auc_score(real, outputs), 3)\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr,label=\"CPTAC, AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('plots/tcia_kfold_roccurve_patient.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(real, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b37585",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, target_names = ['Control', 'Tumor'], normalize = False, filename = 'plots/cm_10fold_tcia_patient.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f608cdf8",
   "metadata": {},
   "source": [
    "## K-FOLD Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaae569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('runs/tcia_kfold_country/test_results.pkl', 'rb') as f:\n",
    "    data_tcia_country = pickle.load(f)\n",
    "countries = ['Bulgaria', 'Canada', 'China', 'Denmark', 'India', 'Iraq', 'Other',\n",
    "       'Poland', 'Russia', 'Serbia', 'South Wales', 'United States']\n",
    "outputs = []\n",
    "real = []\n",
    "accs = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "probabilities = []\n",
    "preds_per_country = []\n",
    "for split in data_tcia_country.keys():\n",
    "    test = data_tcia_country[split]\n",
    "    real_test = np.concatenate(data_tcia_country[split]['real'], axis=0).astype(np.int32)\n",
    "    preds = np.concatenate(data_tcia_country[split]['predictions'], axis=0).astype(np.int32)\n",
    "    patient_ids = np.concatenate(data_tcia_country[split]['patient_ids'], axis=0)\n",
    "    probs = np.concatenate(data_tcia_country[split]['outputs'],axis=0).astype(np.float32)\n",
    "    new_preds = []\n",
    "    new_real = []\n",
    "    new_outputs = []\n",
    "    for pidx in np.unique(patient_ids):\n",
    "        index = np.where(patient_ids == pidx)[0]\n",
    "        if len(index) == 1:\n",
    "            new_preds.append(preds[index[0]])\n",
    "            new_real.append(real_test[index[0]])\n",
    "            new_outputs.append(probs[index[0]])\n",
    "        else:\n",
    "            new_probs = np.mean(probs[index], axis=0)\n",
    "            n_ = softmax(new_probs)\n",
    "            new_outputs.append(n_)\n",
    "            new_preds.append(np.argmax(n_))\n",
    "            new_real.append(real_test[index[0]])\n",
    "    \n",
    "    acc = accuracy_score(new_real, new_preds)\n",
    "    f1 = f1_score(new_real, new_preds, average=\"weighted\")\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)\n",
    "    real.append(new_real)\n",
    "    outputs.append(new_preds)\n",
    "    probabilities.append(new_outputs)\n",
    "    preds_per_country.append(len(new_real))\n",
    "\n",
    "print(f'CPTAC k-Fold per country')\n",
    "print(f'Acc {round(np.mean(acc)*100,3)} +- {round(np.std(accs)*100, 3)}')\n",
    "print(f'F1-score {round(np.mean(f1s)*100,3)} +- {round(np.std(f1s)*100, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2edfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy only with the countries with more samples\n",
    "idx_countries = [1,2,6,7,8,11]\n",
    "print(f'TCIA k-Fold countries with more samples')\n",
    "print(f'Acc {round(np.mean(np.array(accs)[idx_countries])*100,3)} +- {round(np.std(np.array(accs)[idx_countries])*100, 3)}')\n",
    "print(f'F1-score {round(np.mean(np.array(f1s)[idx_countries])*100,3)} +- {round(np.std(np.array(f1s)[idx_countries])*100, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c183c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "country_df = pd.DataFrame()\n",
    "country_df['acc'] = accs\n",
    "country_df['f1-score'] = f1s\n",
    "country_df['country'] = countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3b16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.bar(countries, np.array(accs)*100)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/kfold_countries_cptac_accs.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebef9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.bar(countries, np.array(f1s)*100)\n",
    "plt.xticks(list(range(len(countries))), countries, alpha=0.8)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('F1-Score')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/kfold_countries_cptac_f1score.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676aad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "x = {k: v for k, v in zip(countries, preds_per_country)}\n",
    "new_dict = {k: v for k, v in sorted(x.items(), key=lambda item: item[1])}\n",
    "plt.barh(list(new_dict.keys()), list(new_dict.values()))\n",
    "plt.yticks(list(range(len(new_dict.keys()))), list(new_dict.keys()), alpha=0.8)\n",
    "plt.xticks(list(range(len(new_dict.keys()))), '', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Number of patients')\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/countries_patients.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3938f154",
   "metadata": {},
   "source": [
    "## Generalization experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('runs/tcga_gtex_on_tcia_reinhard_fast_patient/test_results_evaluation.pkl', 'rb') as f:\n",
    "    data_tcga_gtex_on_tcia = pickle.load(f)\n",
    "\n",
    "with open('runs/tcia_on_tcgagtex_reinhard_fast_40_patient/test_results_evaluation.pkl', 'rb') as f:\n",
    "    data_tcia_on_tcga_gtex = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e8f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = np.concatenate(data_tcia_on_tcga_gtex['real'], axis=0).astype(np.int32)\n",
    "preds = np.concatenate(data_tcia_on_tcga_gtex['predictions'], axis=0).astype(np.int32)\n",
    "patient_ids = np.concatenate(data_tcia_on_tcga_gtex['patient_ids'], axis=0)\n",
    "probs = np.concatenate(data_tcia_on_tcga_gtex['outputs'],axis=0).astype(np.float)\n",
    "new_preds = []\n",
    "new_real = []\n",
    "new_outputs = []\n",
    "for pidx in np.unique(patient_ids):\n",
    "    index = np.where(patient_ids == pidx)[0]\n",
    "    if len(index) == 1:\n",
    "        new_preds.append(preds[index[0]])\n",
    "        new_real.append(real_test[index[0]])\n",
    "        new_outputs.append(probs[index[0]])\n",
    "    else:\n",
    "        new_probs = np.mean(probs[index], axis=0)\n",
    "        n_ = softmax(new_probs)\n",
    "        new_outputs.append(n_)\n",
    "        new_preds.append(np.argmax(n_))\n",
    "        new_real.append(real_test[index[0]])\n",
    "            \n",
    "acc = accuracy_score(new_real, new_preds)\n",
    "f1 = f1_score(new_real, new_preds, average=\"weighted\")\n",
    "auc = roc_auc_score(new_real, new_preds)\n",
    "\n",
    "print(f'CPTAC on TCGA-GTEX')\n",
    "print(f'Acc {round(acc*100,3)}')\n",
    "print(f'F1-score {round(f1*100,3)}')\n",
    "print(f'AUC {round(auc,3)}')\n",
    "\n",
    "cm = confusion_matrix(new_real, new_preds)\n",
    "plot_confusion_matrix(cm, target_names = ['Control', 'Tumor'], normalize = False, filename = 'plots/tcia_on_tcga_gtex_patient.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = np.concatenate(data_tcga_gtex_on_tcia['real'], axis=0).astype(np.int32)\n",
    "preds = np.concatenate(data_tcga_gtex_on_tcia['predictions'], axis=0).astype(np.int32)\n",
    "\n",
    "patient_ids = np.concatenate(data_tcga_gtex_on_tcia['patient_ids'], axis=0)\n",
    "probs = np.concatenate(data_tcga_gtex_on_tcia['outputs'],axis=0).astype(np.float)\n",
    "new_preds = []\n",
    "new_real = []\n",
    "new_outputs = []\n",
    "for pidx in np.unique(patient_ids):\n",
    "    index = np.where(patient_ids == pidx)[0]\n",
    "    if len(index) == 1:\n",
    "        new_preds.append(preds[index[0]])\n",
    "        new_real.append(real_test[index[0]])\n",
    "        new_outputs.append(probs[index[0]])\n",
    "    else:\n",
    "        counts = np.bincount(preds[index])\n",
    "        new_preds.append(np.argmax(counts))\n",
    "        #n_ = softmax(new_probs)\n",
    "        #new_outputs.append(n_)\n",
    "        #new_preds.append(np.argmax(n_))\n",
    "        new_real.append(real_test[index[0]])\n",
    "        \n",
    "acc = accuracy_score(new_real, new_preds)\n",
    "f1 = f1_score(new_real, new_preds, average=\"weighted\")\n",
    "auc = roc_auc_score(new_real, new_preds)\n",
    "\n",
    "print(f'TCGA-GTEX on CPTAC')\n",
    "print(f'Acc {round(acc*100,3)}')\n",
    "print(f'F1-score {round(f1*100,3)}')\n",
    "print(f'AUC {round(auc,3)}')\n",
    "\n",
    "cm = confusion_matrix(new_real, new_preds)\n",
    "plot_confusion_matrix(cm, target_names = ['Control', 'Tumor'], normalize = False, filename = 'plots/tcga_gtex_on_tcia_patient.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73edc456",
   "metadata": {},
   "source": [
    "## Results on external dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('runs/tcgagtex_on_mhmc_reinhard_fast_patient/test_results_evaluation.pkl', 'rb') as f:\n",
    "    data_tcga_gtex_on_mhmc = pickle.load(f)\n",
    "\n",
    "with open('runs/tcia_on_mhmc_reinhard_fast_patient/test_results_evaluation.pkl', 'rb') as f:\n",
    "    data_tcia_on_mhmc = pickle.load(f)\n",
    "\n",
    "with open('runs/tcga_gtex_cptac_on_mhmc_reinhard_fast_patient/test_results_evaluation.pkl', 'rb') as f:\n",
    "    data_tcga_gtex_tcia_on_mhmc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed164eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "real_test = np.concatenate(data_tcia_on_mhmc['real'], axis=0).astype(np.int32)\n",
    "preds = np.concatenate(data_tcia_on_mhmc['predictions'], axis=0).astype(np.int32)\n",
    "\n",
    "patient_ids = np.concatenate(data_tcia_on_mhmc['patient_ids'], axis=0)\n",
    "types = [patient_id.split('/')[-2] for patient_id in patient_ids]\n",
    "patient_ids = [type_+'_'+patient_id.split('/')[-1].split('_')[0]+'_'+patient_id.split('/')[-1].split('_')[-1].split('-')[0] for type_,patient_id in zip(types,patient_ids)]\n",
    "patient_ids = np.array(patient_ids)\n",
    "import pdb; pdb.set_trace()\n",
    "probs = np.concatenate(data_tcia_on_mhmc['outputs'],axis=0).astype(np.float)\n",
    "new_preds = []\n",
    "new_real = []\n",
    "new_outputs = []\n",
    "for pidx in np.unique(patient_ids):\n",
    "    index = np.where(patient_ids == pidx)[0]\n",
    "    if len(index) == 1:\n",
    "        new_preds.append(preds[index[0]])\n",
    "        new_real.append(real_test[index[0]])\n",
    "        new_outputs.append(probs[index[0]])\n",
    "    else:\n",
    "        new_probs = np.mean(probs[index], axis=0)\n",
    "        n_ = softmax(new_probs)\n",
    "        new_outputs.append(n_)\n",
    "        new_preds.append(np.argmax(n_))\n",
    "        new_real.append(real_test[index[0]])\n",
    "        \n",
    "acc = accuracy_score(new_real, new_preds)\n",
    "f1 = f1_score(new_real, new_preds, average=\"weighted\")\n",
    "auc = roc_auc_score(new_real, new_preds)\n",
    "\n",
    "print(f'CPTAC on MHMC')\n",
    "print(f'Acc {round(acc*100,3)}')\n",
    "print(f'F1-score {round(f1*100,3)}')\n",
    "print(f'AUC {round(auc,3)}')\n",
    "\n",
    "new_outputs = np.array(new_outputs) \n",
    "cm = confusion_matrix(new_real, new_preds)\n",
    "plot_confusion_matrix(cm, target_names = ['Control', 'Tumor'], normalize = False, filename = 'plots/tcia_on_mhmc_patient.png')\n",
    "fpr, tpr, _ = roc_curve(new_real, new_outputs[:,1])\n",
    "auc = round(roc_auc_score(new_real, new_preds), 3)\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr,label=\"CPTAC on MHMC, AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('plots/tcia_on_mhmc_roccurve_patient.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431943d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "real_test = np.concatenate(data_tcga_gtex_on_mhmc['real'], axis=0).astype(np.int32)\n",
    "preds = np.concatenate(data_tcga_gtex_on_mhmc['predictions'], axis=0).astype(np.int32)\n",
    "patient_ids = np.concatenate(data_tcga_gtex_on_mhmc['patient_ids'], axis=0)\n",
    "types = [patient_id.split('/')[-2] for patient_id in patient_ids]\n",
    "patient_ids = [type_+'_'+patient_id.split('/')[-1].split('_')[0]+'_'+patient_id.split('/')[-1].split('_')[-1].split('-')[0] for type_,patient_id in zip(types,patient_ids)]\n",
    "patient_ids = np.array(patient_ids)\n",
    "probs = np.concatenate(data_tcga_gtex_on_mhmc['outputs'],axis=0).astype(np.float)\n",
    "new_preds = []\n",
    "new_real = []\n",
    "new_outputs = []\n",
    "for pidx in np.unique(patient_ids):\n",
    "    index = np.where(patient_ids == pidx)[0]\n",
    "    if len(index) == 1:\n",
    "        new_preds.append(preds[index[0]])\n",
    "        new_real.append(real_test[index[0]])\n",
    "        new_outputs.append(softmax(probs[index[0]]))\n",
    "    else:\n",
    "        new_probs = np.mean(probs[index], axis=0)\n",
    "        n_ = softmax(new_probs)\n",
    "        new_outputs.append(n_)\n",
    "        new_preds.append(np.argmax(n_))\n",
    "        new_real.append(real_test[index[0]])\n",
    "\n",
    "new_outputs = np.array(new_outputs)   \n",
    "acc = accuracy_score(new_real, new_preds)\n",
    "f1 = f1_score(new_real, new_preds, average=\"weighted\")\n",
    "auc = roc_auc_score(new_real, new_preds)\n",
    "print(f'TCGA-GTEX on MHMC')\n",
    "print(f'Acc {round(acc*100,3)}')\n",
    "print(f'F1-score {round(f1*100,3)}')\n",
    "print(f'AUC {round(auc,3)}')\n",
    "\n",
    "cm = confusion_matrix(new_real, new_preds)\n",
    "plot_confusion_matrix(cm, target_names = ['Control', 'Tumor'], normalize = False, filename = 'plots/tcga_gtex_on_mhmc_patient.png')\n",
    "\n",
    "#RocCurveDisplay.from_predictions(new_real, new_outputs[:,1], name='TCGA+GTEx on MHMC')\n",
    "#plt.savefig('plots/tcga_gtex_on_mhmc_roccurve_patient.png')\n",
    "fpr, tpr, _ = roc_curve(new_real, new_outputs[:,1])\n",
    "auc = round(roc_auc_score(new_real, new_preds), 3)\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr,label=\"TCGA+GTEx on MHMC, AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('plots/tcga_gtex_on_mhmc_roccurve_patient.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = np.concatenate(data_tcga_gtex_tcia_on_mhmc['real'], axis=0).astype(np.int32)\n",
    "preds = np.concatenate(data_tcga_gtex_tcia_on_mhmc['predictions'], axis=0).astype(np.int32)\n",
    "patient_ids = np.concatenate(data_tcga_gtex_tcia_on_mhmc['patient_ids'], axis=0)\n",
    "types = [patient_id.split('/')[-2] for patient_id in patient_ids]\n",
    "patient_ids = [type_+'_'+patient_id.split('/')[-1].split('_')[0]+'_'+patient_id.split('/')[-1].split('_')[-1].split('-')[0] for type_,patient_id in zip(types,patient_ids)]\n",
    "patient_ids = np.array(patient_ids)\n",
    "probs = np.concatenate(data_tcga_gtex_tcia_on_mhmc['outputs'],axis=0).astype(np.float32)\n",
    "new_preds = []\n",
    "new_real = []\n",
    "new_outputs = []\n",
    "for pidx in np.unique(patient_ids):\n",
    "    index = np.where(patient_ids == pidx)[0]\n",
    "    if len(index) == 1:\n",
    "        new_preds.append(preds[index[0]])\n",
    "        new_real.append(real_test[index[0]])\n",
    "        new_outputs.append(softmax(probs[index[0]]))\n",
    "    else:\n",
    "        new_probs = np.mean(probs[index], axis=0)\n",
    "        n_ = softmax(new_probs)\n",
    "        new_outputs.append(n_)\n",
    "        new_preds.append(np.argmax(n_))\n",
    "        new_real.append(real_test[index[0]])\n",
    "\n",
    "new_outputs = np.array(new_outputs)   \n",
    "acc = accuracy_score(new_real, new_preds)\n",
    "f1 = f1_score(new_real, new_preds, average=\"weighted\")\n",
    "auc = roc_auc_score(new_real, new_preds)\n",
    "print(f'TCGA-GTEX+CPTAC on MHMC')\n",
    "print(f'Acc {round(acc*100,3)}')\n",
    "print(f'F1-score {round(f1*100,3)}')\n",
    "print(f'AUC {round(auc,3)}')\n",
    "\n",
    "cm = confusion_matrix(new_real, new_preds)\n",
    "plot_confusion_matrix(cm, target_names = ['Control', 'Tumor'], normalize = False, filename = 'plots/tcga_gtex_tcia_on_mhmc_patient.png')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(new_real, new_outputs[:,1])\n",
    "auc = round(roc_auc_score(new_real, new_preds), 3)\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr,label=\"CPTAC+TCGA+GTEx, AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('plots/tcga_gtex_tcia_on_mhmc_roccurve_patient.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab97575",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_tcga = np.concatenate(data_tcga_gtex_on_mhmc['real'], axis=0).astype(np.int32)\n",
    "preds_tcga = np.concatenate(data_tcga_gtex_on_mhmc['outputs'], axis=0).astype(np.int32)\n",
    "patient_ids = np.concatenate(data_tcga_gtex_on_mhmc['patient_ids'], axis=0)\n",
    "types = [patient_id.split('/')[-2] for patient_id in patient_ids]\n",
    "patient_ids = [type_+'_'+patient_id.split('/')[-1].split('_')[0]+'_'+patient_id.split('/')[-1].split('_')[-1].split('-')[0] for type_,patient_id in zip(types,patient_ids)]\n",
    "patient_ids = np.array(patient_ids)\n",
    "probs_tcga = np.concatenate(data_tcga_gtex_on_mhmc['outputs'],axis=0).astype(np.float32)\n",
    "new_preds_tcga = []\n",
    "new_real_tcga = []\n",
    "new_outputs_tcga = []\n",
    "for pidx in np.unique(patient_ids):\n",
    "    index = np.where(patient_ids == pidx)[0]\n",
    "    if len(index) == 1:\n",
    "        new_preds_tcga.append(preds_tcga[index[0]])\n",
    "        new_real_tcga.append(real_test_tcga[index[0]])\n",
    "        new_outputs_tcga.append(softmax(probs_tcga[index[0]]))\n",
    "    else:\n",
    "        new_probs = np.mean(probs_tcga[index], axis=0)\n",
    "        n_ = softmax(new_probs)\n",
    "        new_outputs_tcga.append(n_)\n",
    "        new_preds_tcga.append(np.argmax(n_))\n",
    "        new_real_tcga.append(real_test_tcga[index[0]])\n",
    "new_outputs_tcga = np.array(new_outputs_tcga)\n",
    "fpr, tpr, _ = roc_curve(new_real_tcga, new_outputs_tcga[:,1])\n",
    "auc = round(roc_auc_score(new_real_tcga, new_outputs_tcga[:,1]), 3)\n",
    "plt.plot(fpr,tpr,label=\"TCGA+GTEX, AUC=\"+str(auc))\n",
    "\n",
    "real_test_tcia = np.concatenate(data_tcia_on_mhmc['real'], axis=0).astype(np.int32)\n",
    "preds_tcia = np.concatenate(data_tcia_on_mhmc['outputs'], axis=0).astype(np.int32)\n",
    "patient_ids = np.concatenate(data_tcia_on_mhmc['patient_ids'], axis=0)\n",
    "types = [patient_id.split('/')[-2] for patient_id in patient_ids]\n",
    "patient_ids = [type_+'_'+patient_id.split('/')[-1].split('_')[0]+'_'+patient_id.split('/')[-1].split('_')[-1].split('-')[0] for type_,patient_id in zip(types,patient_ids)]\n",
    "patient_ids = np.array(patient_ids)\n",
    "probs_tcia = np.concatenate(data_tcia_on_mhmc['outputs'],axis=0).astype(np.float32)\n",
    "new_preds_tcia = []\n",
    "new_real_tcia = []\n",
    "new_outputs_tcia = []\n",
    "for pidx in np.unique(patient_ids):\n",
    "    index = np.where(patient_ids == pidx)[0]\n",
    "    if len(index) == 1:\n",
    "        new_preds_tcia.append(preds_tcia[index[0]])\n",
    "        new_real_tcia.append(real_test_tcia[index[0]])\n",
    "        new_outputs_tcia.append(softmax(probs_tcia[index[0]]))\n",
    "    else:\n",
    "        new_probs = np.mean(probs_tcia[index], axis=0)\n",
    "        n_ = softmax(new_probs)\n",
    "        new_outputs_tcia.append(n_)\n",
    "        new_preds_tcia.append(np.argmax(n_))\n",
    "        new_real_tcia.append(real_test_tcia[index[0]])\n",
    "new_outputs_tcia = np.array(new_outputs_tcia)\n",
    "fpr, tpr, _ = roc_curve(new_real_tcia, new_outputs_tcia[:,1])\n",
    "auc = round(roc_auc_score(new_real_tcia, new_outputs_tcia[:,1]), 3)\n",
    "plt.plot(fpr,tpr,label=\"CPTAC, AUC=\"+str(auc))\n",
    "\n",
    "real_test_all = np.concatenate(data_tcga_gtex_tcia_on_mhmc['real'], axis=0).astype(np.int32)\n",
    "preds_all = np.concatenate(data_tcga_gtex_tcia_on_mhmc['outputs'], axis=0).astype(np.int32)\n",
    "patient_ids = np.concatenate(data_tcga_gtex_tcia_on_mhmc['patient_ids'], axis=0)\n",
    "types = [patient_id.split('/')[-2] for patient_id in patient_ids]\n",
    "patient_ids = [type_+'_'+patient_id.split('/')[-1].split('_')[0]+'_'+patient_id.split('/')[-1].split('_')[-1].split('-')[0] for type_,patient_id in zip(types,patient_ids)]\n",
    "patient_ids = np.array(patient_ids)\n",
    "probs_all = np.concatenate(data_tcga_gtex_tcia_on_mhmc['outputs'],axis=0).astype(np.float32)\n",
    "new_preds_all = []\n",
    "new_real_all = []\n",
    "new_outputs_all = []\n",
    "for pidx in np.unique(patient_ids):\n",
    "    index = np.where(patient_ids == pidx)[0]\n",
    "    if len(index) == 1:\n",
    "        new_preds_all.append(preds_all[index[0]])\n",
    "        new_real_all.append(real_test_all[index[0]])\n",
    "        new_outputs_all.append(softmax(probs_all[index[0]]))\n",
    "    else:\n",
    "        new_probs = np.mean(probs_all[index], axis=0)\n",
    "        n_ = softmax(new_probs)\n",
    "        new_outputs_all.append(n_)\n",
    "        new_preds_all.append(np.argmax(n_))\n",
    "        new_real_all.append(real_test_all[index[0]])\n",
    "new_outputs_all = np.array(new_outputs_all)\n",
    "fpr, tpr, _ = roc_curve(new_real_all, new_outputs_all[:,1])\n",
    "auc = round(roc_auc_score(new_real_all, new_outputs_all[:,1]), 3)\n",
    "plt.plot(fpr,tpr,label=\"CPTAC+TCGA+GTEX, AUC=\"+str(auc))\n",
    "\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('plots/roc_curve_mhmc_three_patient.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a180e8ed",
   "metadata": {},
   "source": [
    "## Features visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabdcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('runs/tcia_on_mhmc_reinhard_fast/features.pkl', 'rb') as f:\n",
    "    features_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('runs/tcgagtex_fulltrain_reinhard_fast/features.pkl', 'rb') as f:\n",
    "    features_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_data['features']\n",
    "labels = features_data['labels']\n",
    "patient_id = features_data['patient_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f509025",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = [x.split('-')[0] for x in patient_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059ef44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "reducer = umap.UMAP()\n",
    "embedding = reducer.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b276a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "colors = ['red','blue']\n",
    "scatter = plt.scatter(embedding[:,0], embedding[:,1], c=labels, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.legend(handles=scatter.legend_elements()[0], \n",
    "           title=\"Label\",\n",
    "           labels=['Control', 'Tumor'])\n",
    "plt.savefig('plots/features_label_tcgagtex.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aecbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85b6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "project_new = []\n",
    "for x in project:\n",
    "    if x =='TCGA':\n",
    "        project_new.append(1)\n",
    "    elif x =='GTEX':\n",
    "        project_new.append(0)\n",
    "colors = ['red','blue']\n",
    "scatter = plt.scatter(embedding[:,0], embedding[:,1], c=project_new, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "plt.legend(handles=scatter.legend_elements()[0], \n",
    "           title=\"Database\",\n",
    "           labels=['GTEx', 'TCGA'])\n",
    "plt.savefig('plots/features_project_tcgagtex.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a333ce2",
   "metadata": {},
   "source": [
    "## 10-fold all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7becefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('runs/tcia_kfol_tcga_gtex_patient/test_results.pkl', 'rb') as f:\n",
    "    data_tcia = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('runs/tcga_gtex_kfol_tcia_patient/test_results.pkl', 'rb') as f:\n",
    "    data_tcga_gtex = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "real = []\n",
    "accs = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "probabilities = []\n",
    "for split in data_tcga_gtex.keys():\n",
    "    test = data_tcga_gtex[split]\n",
    "    real_test = np.concatenate(data_tcga_gtex[split]['real'], axis=0).astype(np.int32)\n",
    "    preds = np.concatenate(data_tcga_gtex[split]['predictions'], axis=0).astype(np.int32)\n",
    "    patient_ids = np.concatenate(data_tcga_gtex[split]['patient_ids'], axis=0)\n",
    "    probs = np.concatenate(data_tcga_gtex[split]['outputs'],axis=0).astype(np.float32)\n",
    "    new_preds = []\n",
    "    new_real = []\n",
    "    new_outputs = []\n",
    "    for pidx in np.unique(patient_ids):\n",
    "        index = np.where(patient_ids == pidx)[0]\n",
    "        if len(index) == 1:\n",
    "            new_preds.append(preds[index[0]])\n",
    "            new_real.append(real_test[index[0]])\n",
    "            new_outputs.append(probs[index[0]])\n",
    "        else:\n",
    "            new_probs = np.mean(probs[index], axis=0)\n",
    "            n_ = softmax(new_probs)\n",
    "            new_outputs.append(n_)\n",
    "            new_preds.append(np.argmax(n_))\n",
    "            new_real.append(real_test[index[0]])\n",
    "    \n",
    "    acc = accuracy_score(new_real, new_preds)\n",
    "    f1 = f1_score(new_real, new_preds, average=\"weighted\")\n",
    "    auc = roc_auc_score(new_real, new_preds)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)\n",
    "    aucs.append(auc)\n",
    "    real.append(new_real)\n",
    "    outputs.append(new_preds)\n",
    "    probabilities.append(new_outputs)\n",
    "\n",
    "print(f'TCGA-GTEX + TCIA on train')\n",
    "print(f'Acc {round(np.mean(acc)*100,3)} +- {round(np.std(accs)*100, 3)}')\n",
    "print(f'F1-score {round(np.mean(f1s)*100,3)} +- {round(np.std(f1s)*100, 3)}')\n",
    "print(f'AUC {round(np.mean(aucs),3)}+- {round(np.std(aucs)*100, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8715f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "real = []\n",
    "accs = []\n",
    "f1s = []\n",
    "aucs = []\n",
    "probabilities = []\n",
    "for split in data_tcia.keys():\n",
    "    test = data_tcia[split]\n",
    "    real_test = np.concatenate(data_tcia[split]['real'], axis=0).astype(np.int32)\n",
    "    preds = np.concatenate(data_tcia[split]['predictions'], axis=0).astype(np.int32)\n",
    "    patient_ids = np.concatenate(data_tcia[split]['patient_ids'], axis=0)\n",
    "    probs = np.concatenate(data_tcia[split]['outputs'],axis=0).astype(np.float32)\n",
    "    new_preds = []\n",
    "    new_real = []\n",
    "    new_outputs = []\n",
    "    for pidx in np.unique(patient_ids):\n",
    "        index = np.where(patient_ids == pidx)[0]\n",
    "        if len(index) == 1:\n",
    "            new_preds.append(preds[index[0]])\n",
    "            new_real.append(real_test[index[0]])\n",
    "            new_outputs.append(probs[index[0]])\n",
    "        else:\n",
    "            new_probs = np.mean(probs[index], axis=0)\n",
    "            n_ = softmax(new_probs)\n",
    "            new_outputs.append(n_)\n",
    "            new_preds.append(np.argmax(n_))\n",
    "            new_real.append(real_test[index[0]])\n",
    "    \n",
    "    acc = accuracy_score(new_real, new_preds)\n",
    "    f1 = f1_score(new_real, new_preds, average=\"weighted\")\n",
    "    auc = roc_auc_score(new_real, new_preds)\n",
    "    accs.append(acc)\n",
    "    f1s.append(f1)\n",
    "    aucs.append(auc)\n",
    "    real.append(new_real)\n",
    "    outputs.append(new_preds)\n",
    "    probabilities.append(new_outputs)\n",
    "\n",
    "print(f'CPTAC + TCGA-GTEX on train')\n",
    "print(f'Acc {round(np.mean(acc)*100,3)} +- {round(np.std(accs)*100, 3)}')\n",
    "print(f'F1-score {round(np.mean(f1s)*100,3)} +- {round(np.std(f1s)*100, 3)}')\n",
    "print(f'AUC {round(np.mean(aucs),3)}+- {round(np.std(aucs), 3)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "afc85ecab61c6228facc49f409d2cf6884279af7f934fa40855861190c720fcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
